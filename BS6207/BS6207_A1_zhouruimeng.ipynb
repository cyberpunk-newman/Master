{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "derived-rogers",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-watts",
   "metadata": {},
   "source": [
    "# Auto Grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "auburn-wichita",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# device config\n",
    "device = torch.device('cpu')\n",
    "\n",
    "np.random.seed(0)\n",
    "# input nodes\n",
    "x = np.around(np.random.uniform(0, 1, 10), decimals = 3)\n",
    "y = sum(x ** 2) / 10\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "batch_size = 1\n",
    "num_classes = 1\n",
    "input_size = 10\n",
    "hidden_size = 21\n",
    "\n",
    "\n",
    "x = torch.Tensor(x)\n",
    "y = torch.Tensor(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-matthew",
   "metadata": {},
   "source": [
    "# X & Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dental-handbook",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5490, 0.7150, 0.6030, 0.5450, 0.4240, 0.6460, 0.4380, 0.8920, 0.9640,\n",
      "        0.3830])\n",
      "tensor(0.4134)\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "damaged-gates",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nueral Network\n",
    "NeuralNetwork = nn.Sequential(\n",
    "    # input layer\n",
    "    nn.Linear(input_size,hidden_size),\n",
    "    # 2 layer\n",
    "    nn.Linear(hidden_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    # 3 layer\n",
    "    nn.Linear(hidden_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    # 4 layer\n",
    "    nn.Linear(hidden_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    # 5 layer\n",
    "    nn.Linear(hidden_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    # 6 layer\n",
    "    nn.Linear(hidden_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    # 7 layer\n",
    "    nn.Linear(hidden_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    # 8 layer\n",
    "    nn.Linear(hidden_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    # 9 layer\n",
    "    nn.Linear(hidden_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    # 10 layer\n",
    "    nn.Linear(hidden_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    # 11 layer\n",
    "    nn.Linear(hidden_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    # 12 layer\n",
    "    nn.Linear(hidden_size, num_classes)\n",
    "\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "local-marine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=10, out_features=21, bias=True)\n",
      "  (1): Linear(in_features=21, out_features=21, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=21, out_features=21, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Linear(in_features=21, out_features=21, bias=True)\n",
      "  (6): ReLU()\n",
      "  (7): Linear(in_features=21, out_features=21, bias=True)\n",
      "  (8): ReLU()\n",
      "  (9): Linear(in_features=21, out_features=21, bias=True)\n",
      "  (10): ReLU()\n",
      "  (11): Linear(in_features=21, out_features=21, bias=True)\n",
      "  (12): ReLU()\n",
      "  (13): Linear(in_features=21, out_features=21, bias=True)\n",
      "  (14): ReLU()\n",
      "  (15): Linear(in_features=21, out_features=21, bias=True)\n",
      "  (16): ReLU()\n",
      "  (17): Linear(in_features=21, out_features=21, bias=True)\n",
      "  (18): ReLU()\n",
      "  (19): Linear(in_features=21, out_features=21, bias=True)\n",
      "  (20): ReLU()\n",
      "  (21): Linear(in_features=21, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(NeuralNetwork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "involved-steal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "def criterion(predict, y):\n",
    "    L = (predict - y) ** 2\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "mineral-rally",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:  tensor([-0.1228], grad_fn=<AddBackward0>)\n",
      "type outputs:  <class 'torch.Tensor'>\n",
      "type y:  <class 'torch.Tensor'>\n",
      "Loss:  tensor([0.2875], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# implement network\n",
    "outputs = NeuralNetwork(x)\n",
    "print('outputs: ',outputs)\n",
    "print('type outputs: ',type(outputs))\n",
    "print('type y: ',type(y))\n",
    "Loss = criterion(outputs, y)\n",
    "\n",
    "# backward torch\n",
    "Loss.backward()\n",
    "print('Loss: ',Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "noticed-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 1\n",
    "for i in range(1, 22, 2):\n",
    "    print(f'{j} auto_weight is:  {NeuralNetwork[i].weight.grad}')\n",
    "    j += 1\n",
    "\n",
    "j = 1\n",
    "for i in range(1, 22, 2):\n",
    "    print(f'{j} auto_bias is:  {NeuralNetwork[i].bias.grad}')\n",
    "    j += 1\n",
    "\n",
    "\n",
    "j = 1\n",
    "fo = open('D:/PG_study/BS6207/Assignment/torch_autograd.dat', 'w')\n",
    "for i in range(1, 22, 2):\n",
    "    fo.write('Layer '+str(j)+' auto_weight is'+'\\n'+str(NeuralNetwork[i].weight.grad))\n",
    "    fo.write('\\n')\n",
    "    fo.write('Layer '+str(j)+' auto_bias is'+'\\n'+str(NeuralNetwork[i].bias.grad))\n",
    "    fo.write('\\n')\n",
    "    j += 1\n",
    "fo.close()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-candle",
   "metadata": {},
   "source": [
    "# From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "charming-debut",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for activationa and derivative\n",
    "\n",
    "def criterion(predict, y):\n",
    "    L = (predict - y) ** 2\n",
    "    return L\n",
    "\n",
    "def deri_criterion(predict,y):\n",
    "    L = float(2*(predict-y))\n",
    "    return L\n",
    "\n",
    "def Relu(Z):\n",
    "    return np.maximum(0,Z)\n",
    "\n",
    "\n",
    "def deri_Relu(Z):\n",
    "    return Z>0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "danish-solid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.549 0.715 0.603 0.545 0.424 0.646 0.438 0.892 0.964 0.383]\n"
     ]
    }
   ],
   "source": [
    "x_zrm = x.detach().numpy()\n",
    "print(x_zrm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-glance",
   "metadata": {},
   "source": [
    "# Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "green-westminster",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:  0\n",
      "i:  1\n",
      "i:  2\n",
      "i:  3\n",
      "i:  4\n",
      "i:  5\n",
      "i:  6\n",
      "i:  7\n",
      "i:  8\n",
      "i:  9\n",
      "i:  10\n",
      "i:  11\n",
      "zrm_output[-1]:  [-0.12276714]\n",
      "zrm_Loss:  tensor(0.2875)\n"
     ]
    }
   ],
   "source": [
    "zrm_weight = []\n",
    "zrm_bias = []\n",
    "\n",
    "for i in range(22):\n",
    "    if type(NeuralNetwork[i]) != nn.modules.activation.ReLU:\n",
    "        zrm_weight.append(NeuralNetwork[i].weight.t().detach().numpy())\n",
    "        zrm_bias.append(NeuralNetwork[i].bias.detach().numpy())\n",
    "\n",
    "\n",
    "# this forward is correct\n",
    "def zrm_forward(X):\n",
    "    outputs = []\n",
    "    out = X\n",
    "\n",
    "    for i in range(len(zrm_bias)):\n",
    "        print('i: ',i)\n",
    "        logits = out.dot(zrm_weight[i]) + zrm_bias[i]\n",
    "        if i != 0 and i != 11:\n",
    "            out = Relu(logits)\n",
    "        else:\n",
    "            out = logits\n",
    "        outputs.append(out)\n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n",
    "zrm_output = zrm_forward(x_zrm)\n",
    "print('zrm_output[-1]: ',zrm_output[-1])\n",
    "zrm_Loss = criterion(zrm_output[-1][0], y)\n",
    "\n",
    "print('zrm_Loss: ',zrm_Loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cheap-emergency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zrm_output[-1]:  [-0.1228]\n",
      "auto outputs:  tensor([-0.1228], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('zrm_output[-1]: ',np.around(zrm_output[-1],4))\n",
    "print('auto outputs: ',outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-northern",
   "metadata": {},
   "source": [
    "# Backward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "electoral-banner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y.numpy:  0.4133845\n",
      "Layer 11 bias:  [-1.07233429]\n",
      "Hidden layer 1 bias_gradients is: [-0.0001 -0.0001  0.      0.     -0.     -0.      0.     -0.0001  0.\n",
      " -0.      0.     -0.0001 -0.     -0.0001 -0.     -0.0001  0.      0.\n",
      "  0.      0.      0.    ]\n",
      "Hidden layer 2 bias_gradients is: [ 0.      0.      0.      0.     -0.0001  0.0001  0.     -0.0001  0.\n",
      "  0.      0.      0.      0.     -0.     -0.0001 -0.0002 -0.0001 -0.0001\n",
      "  0.      0.     -0.0002]\n",
      "Hidden layer 3 bias_gradients is: [ 0.      0.     -0.0002 -0.0002  0.      0.0001  0.0003 -0.0001  0.\n",
      "  0.     -0.0005  0.0004  0.      0.0002 -0.      0.      0.0002  0.\n",
      " -0.0004  0.      0.    ]\n",
      "Hidden layer 4 bias_gradients is: [ 0.      0.0003 -0.0006  0.     -0.0006  0.0006  0.0015 -0.0009  0.0003\n",
      "  0.      0.      0.     -0.001   0.     -0.0008  0.      0.      0.\n",
      "  0.      0.      0.    ]\n",
      "Hidden layer 5 bias_gradients is: [ 0.0013  0.0018  0.0019  0.      0.0027  0.001   0.      0.      0.\n",
      "  0.0017  0.     -0.0014  0.     -0.001   0.      0.0024  0.0014  0.\n",
      "  0.      0.      0.    ]\n",
      "Hidden layer 6 bias_gradients is: [ 0.0003  0.      0.0049  0.      0.     -0.002   0.0045  0.      0.0028\n",
      "  0.      0.008   0.      0.0035  0.      0.     -0.004   0.003   0.\n",
      "  0.0032  0.     -0.0048]\n",
      "Hidden layer 7 bias_gradients is: [-0.0067  0.0102  0.0011  0.      0.      0.009   0.      0.0104  0.0023\n",
      "  0.0003 -0.0001  0.     -0.0097  0.      0.      0.0026  0.      0.\n",
      "  0.0054 -0.015   0.0093]\n",
      "Hidden layer 8 bias_gradients is: [ 0.      0.     -0.0123 -0.0306  0.     -0.0308  0.      0.      0.\n",
      "  0.      0.0271  0.     -0.004   0.0264  0.     -0.0244  0.0361  0.\n",
      " -0.0214  0.      0.0335]\n",
      "Hidden layer 9 bias_gradients is: [-0.0173  0.1077 -0.0026 -0.0376  0.      0.      0.      0.      0.\n",
      " -0.027   0.0189  0.0663  0.     -0.044   0.      0.      0.07    0.\n",
      "  0.     -0.0668  0.0263]\n",
      "Hidden layer 10 bias_gradients is: [ 0.      0.0464  0.      0.     -0.116   0.     -0.1524  0.202   0.1415\n",
      " -0.1721 -0.2039  0.     -0.1506  0.      0.      0.     -0.0314  0.\n",
      "  0.1183  0.      0.0694]\n",
      "Hidden layer 1 weight_gradients is: [[ 0.      0.     -0.     -0.      0.      0.     -0.      0.     -0.\n",
      "   0.      0.      0.      0.      0.      0.      0.     -0.      0.\n",
      "   0.      0.     -0.    ]\n",
      " [ 0.      0.     -0.     -0.      0.      0.     -0.      0.     -0.\n",
      "   0.      0.      0.      0.      0.      0.      0.     -0.      0.\n",
      "   0.      0.     -0.    ]\n",
      " [ 0.0001  0.0001 -0.     -0.      0.      0.     -0.      0.0001 -0.\n",
      "   0.      0.      0.0001  0.      0.0001  0.      0.0001 -0.      0.\n",
      "   0.      0.     -0.    ]\n",
      " [ 0.      0.     -0.     -0.      0.      0.     -0.      0.     -0.\n",
      "   0.      0.      0.      0.      0.      0.      0.     -0.      0.\n",
      "   0.      0.     -0.    ]\n",
      " [ 0.      0.     -0.     -0.      0.      0.     -0.      0.     -0.\n",
      "   0.      0.      0.      0.      0.      0.      0.     -0.      0.\n",
      "   0.      0.     -0.    ]\n",
      " [ 0.      0.     -0.     -0.      0.      0.     -0.      0.     -0.\n",
      "   0.      0.      0.      0.      0.      0.      0.     -0.      0.\n",
      "   0.      0.     -0.    ]\n",
      " [-0.0001 -0.0001  0.      0.     -0.     -0.      0.     -0.0001  0.\n",
      "  -0.     -0.     -0.0001 -0.     -0.0001 -0.     -0.0001  0.     -0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.      0.     -0.     -0.      0.      0.     -0.      0.     -0.\n",
      "   0.      0.      0.      0.      0.      0.      0.0001 -0.      0.\n",
      "   0.      0.     -0.    ]\n",
      " [ 0.      0.     -0.     -0.      0.      0.     -0.      0.     -0.\n",
      "   0.      0.      0.      0.      0.      0.      0.     -0.      0.\n",
      "   0.      0.     -0.    ]\n",
      " [ 0.      0.     -0.     -0.      0.      0.     -0.      0.     -0.\n",
      "   0.      0.      0.      0.      0.      0.      0.     -0.      0.\n",
      "   0.      0.     -0.    ]\n",
      " [ 0.      0.     -0.     -0.      0.      0.     -0.      0.     -0.\n",
      "   0.      0.      0.      0.      0.      0.      0.     -0.      0.\n",
      "   0.      0.     -0.    ]\n",
      " [ 0.      0.     -0.     -0.      0.      0.     -0.      0.     -0.\n",
      "   0.      0.      0.      0.      0.      0.      0.     -0.      0.\n",
      "   0.      0.     -0.    ]\n",
      " [-0.     -0.      0.      0.     -0.     -0.      0.     -0.      0.\n",
      "  -0.     -0.     -0.     -0.     -0.     -0.     -0.      0.     -0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.      0.     -0.     -0.      0.      0.     -0.      0.     -0.\n",
      "   0.      0.      0.      0.      0.      0.      0.     -0.      0.\n",
      "   0.      0.     -0.    ]\n",
      " [ 0.      0.     -0.     -0.      0.      0.     -0.      0.     -0.\n",
      "   0.      0.      0.      0.      0.      0.      0.     -0.      0.\n",
      "   0.      0.     -0.    ]\n",
      " [ 0.      0.     -0.     -0.      0.      0.     -0.      0.     -0.\n",
      "   0.      0.      0.      0.      0.      0.      0.     -0.      0.\n",
      "   0.      0.     -0.    ]\n",
      " [ 0.0001  0.0001 -0.     -0.      0.      0.     -0.      0.0001 -0.\n",
      "   0.      0.      0.0001  0.      0.0001  0.      0.0001 -0.      0.\n",
      "   0.      0.     -0.    ]\n",
      " [-0.     -0.      0.      0.     -0.     -0.      0.     -0.      0.\n",
      "  -0.     -0.     -0.     -0.     -0.     -0.     -0.      0.     -0.\n",
      "  -0.     -0.      0.    ]\n",
      " [-0.     -0.      0.      0.     -0.     -0.      0.     -0.      0.\n",
      "  -0.     -0.     -0.     -0.     -0.     -0.     -0.      0.     -0.\n",
      "  -0.     -0.      0.    ]\n",
      " [-0.     -0.      0.      0.     -0.     -0.      0.     -0.      0.\n",
      "  -0.     -0.     -0.     -0.     -0.     -0.     -0.      0.     -0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.      0.     -0.     -0.      0.      0.     -0.      0.     -0.\n",
      "   0.      0.      0.      0.      0.      0.      0.     -0.      0.\n",
      "   0.      0.     -0.    ]]\n",
      "Hidden layer 2 weight_gradients is: [[ 0.      0.      0.      0.     -0.0001  0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.     -0.0001 -0.0001 -0.0001 -0.0001\n",
      "  -0.      0.     -0.0001]\n",
      " [ 0.      0.      0.      0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.     -0.     -0.0001 -0.     -0.\n",
      "  -0.      0.     -0.0001]\n",
      " [ 0.      0.      0.      0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.     -0.     -0.     -0.     -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.      0.      0.      0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.     -0.     -0.     -0.     -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.      0.      0.      0.     -0.0001  0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.     -0.     -0.0001 -0.0001 -0.0001\n",
      "  -0.      0.     -0.0001]\n",
      " [ 0.      0.      0.      0.     -0.0001  0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.     -0.     -0.0001 -0.0001 -0.0001\n",
      "  -0.      0.     -0.0001]\n",
      " [ 0.      0.      0.      0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.     -0.     -0.     -0.     -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.      0.      0.      0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.     -0.     -0.0001 -0.     -0.\n",
      "  -0.      0.     -0.0001]\n",
      " [ 0.      0.      0.      0.     -0.0001  0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.     -0.     -0.0001 -0.0001 -0.0001\n",
      "  -0.      0.     -0.0001]\n",
      " [ 0.      0.      0.      0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.     -0.     -0.     -0.     -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.      0.      0.      0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.     -0.     -0.     -0.     -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.      0.      0.      0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.     -0.     -0.     -0.     -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.      0.      0.      0.     -0.0001  0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.     -0.     -0.0001 -0.0001 -0.0001\n",
      "  -0.      0.     -0.0001]\n",
      " [ 0.      0.      0.      0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.     -0.     -0.     -0.     -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.      0.      0.      0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.     -0.     -0.0001 -0.     -0.\n",
      "  -0.      0.     -0.0001]\n",
      " [ 0.      0.      0.      0.     -0.0001  0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.     -0.     -0.0001 -0.0001 -0.\n",
      "  -0.      0.     -0.0001]\n",
      " [ 0.      0.      0.      0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.     -0.     -0.     -0.     -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.      0.      0.      0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.     -0.     -0.     -0.     -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.      0.      0.      0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.     -0.     -0.     -0.     -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.      0.      0.      0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.     -0.     -0.     -0.     -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.      0.      0.      0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.     -0.     -0.     -0.     -0.\n",
      "  -0.      0.     -0.    ]]\n",
      "Hidden layer 3 weight_gradients is: [[ 0.     -0.     -0.     -0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.     -0.      0.     -0.      0.     -0.     -0.      0.      0.\n",
      "  -0.      0.      0.    ]\n",
      " [ 0.     -0.     -0.     -0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.     -0.      0.     -0.      0.     -0.     -0.      0.      0.\n",
      "  -0.      0.      0.    ]\n",
      " [ 0.     -0.     -0.     -0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.     -0.      0.     -0.      0.     -0.     -0.      0.      0.\n",
      "  -0.      0.      0.    ]\n",
      " [ 0.     -0.     -0.     -0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.     -0.      0.     -0.      0.     -0.     -0.      0.      0.\n",
      "  -0.      0.      0.    ]\n",
      " [ 0.     -0.     -0.     -0.0001 -0.      0.      0.0001 -0.     -0.\n",
      "  -0.     -0.0002  0.0001 -0.      0.     -0.     -0.      0.      0.\n",
      "  -0.0001  0.      0.    ]\n",
      " [ 0.     -0.     -0.     -0.     -0.      0.      0.0001 -0.     -0.\n",
      "  -0.     -0.0001  0.0001 -0.      0.     -0.     -0.      0.      0.\n",
      "  -0.0001  0.      0.    ]\n",
      " [ 0.     -0.     -0.     -0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.     -0.      0.     -0.      0.     -0.     -0.      0.      0.\n",
      "  -0.      0.      0.    ]\n",
      " [ 0.     -0.     -0.     -0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.     -0.      0.     -0.      0.     -0.     -0.      0.      0.\n",
      "  -0.      0.      0.    ]\n",
      " [ 0.     -0.     -0.     -0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.     -0.      0.     -0.      0.     -0.     -0.      0.      0.\n",
      "  -0.      0.      0.    ]\n",
      " [ 0.     -0.     -0.     -0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.     -0.      0.     -0.      0.     -0.     -0.      0.      0.\n",
      "  -0.      0.      0.    ]\n",
      " [ 0.     -0.     -0.     -0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.     -0.0001  0.0001 -0.      0.     -0.     -0.      0.      0.\n",
      "  -0.0001  0.      0.    ]\n",
      " [ 0.     -0.     -0.     -0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.     -0.      0.     -0.      0.     -0.     -0.      0.      0.\n",
      "  -0.      0.      0.    ]\n",
      " [ 0.     -0.     -0.     -0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.     -0.0001  0.0001 -0.      0.     -0.     -0.      0.      0.\n",
      "  -0.0001  0.      0.    ]\n",
      " [ 0.     -0.     -0.     -0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.     -0.0001  0.     -0.      0.     -0.     -0.      0.      0.\n",
      "  -0.      0.      0.    ]\n",
      " [ 0.     -0.     -0.     -0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.     -0.      0.     -0.      0.     -0.     -0.      0.      0.\n",
      "  -0.      0.      0.    ]\n",
      " [ 0.     -0.     -0.     -0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.     -0.      0.     -0.      0.     -0.     -0.      0.      0.\n",
      "  -0.      0.      0.    ]\n",
      " [ 0.     -0.     -0.     -0.     -0.      0.      0.0001 -0.     -0.\n",
      "  -0.     -0.0001  0.0001 -0.      0.     -0.     -0.      0.      0.\n",
      "  -0.0001  0.      0.    ]\n",
      " [ 0.     -0.     -0.0001 -0.0001 -0.      0.      0.0001 -0.0001 -0.\n",
      "  -0.     -0.0002  0.0001 -0.      0.0001 -0.     -0.      0.0001  0.\n",
      "  -0.0002  0.      0.    ]\n",
      " [ 0.     -0.     -0.     -0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.     -0.      0.     -0.      0.     -0.     -0.      0.      0.\n",
      "  -0.      0.      0.    ]\n",
      " [ 0.     -0.     -0.     -0.     -0.      0.      0.     -0.     -0.\n",
      "  -0.     -0.      0.     -0.      0.     -0.     -0.      0.      0.\n",
      "  -0.      0.      0.    ]\n",
      " [ 0.     -0.     -0.     -0.     -0.      0.      0.0001 -0.     -0.\n",
      "  -0.     -0.0001  0.0001 -0.      0.     -0.     -0.      0.      0.\n",
      "  -0.0001  0.      0.    ]]\n",
      "Hidden layer 4 weight_gradients is: [[ 0.      0.     -0.      0.     -0.      0.      0.     -0.      0.\n",
      "   0.     -0.     -0.     -0.      0.     -0.      0.      0.     -0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.      0.     -0.      0.     -0.      0.      0.     -0.      0.\n",
      "   0.     -0.     -0.     -0.      0.     -0.      0.      0.     -0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.      0.     -0.      0.     -0.      0.      0.0001 -0.0001  0.\n",
      "   0.     -0.     -0.     -0.0001  0.     -0.0001  0.      0.     -0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.      0.     -0.0001  0.     -0.0001  0.0001  0.0002 -0.0001  0.\n",
      "   0.     -0.     -0.     -0.0001  0.     -0.0001  0.      0.     -0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.      0.     -0.      0.     -0.      0.      0.     -0.      0.\n",
      "   0.     -0.     -0.     -0.      0.     -0.      0.      0.     -0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.      0.     -0.0001  0.     -0.0001  0.0001  0.0002 -0.0001  0.\n",
      "   0.     -0.     -0.     -0.0001  0.     -0.0001  0.      0.     -0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.      0.     -0.      0.     -0.      0.      0.     -0.      0.\n",
      "   0.     -0.     -0.     -0.      0.     -0.      0.      0.     -0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.      0.     -0.0001  0.     -0.0001  0.0001  0.0002 -0.0001  0.\n",
      "   0.     -0.     -0.     -0.0001  0.     -0.0001  0.      0.     -0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.      0.     -0.      0.     -0.      0.      0.     -0.      0.\n",
      "   0.     -0.     -0.     -0.      0.     -0.      0.      0.     -0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.      0.     -0.      0.     -0.      0.      0.     -0.      0.\n",
      "   0.     -0.     -0.     -0.      0.     -0.      0.      0.     -0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.      0.     -0.0001  0.     -0.0001  0.0001  0.0002 -0.0001  0.\n",
      "   0.     -0.     -0.     -0.0001  0.     -0.0001  0.      0.     -0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.      0.     -0.0001  0.     -0.0001  0.0001  0.0002 -0.0001  0.\n",
      "   0.     -0.     -0.     -0.0001  0.     -0.0001  0.      0.     -0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.      0.     -0.      0.     -0.      0.      0.     -0.      0.\n",
      "   0.     -0.     -0.     -0.      0.     -0.      0.      0.     -0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.      0.     -0.      0.     -0.      0.      0.0001 -0.0001  0.\n",
      "   0.     -0.     -0.     -0.0001  0.     -0.0001  0.      0.     -0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.      0.     -0.      0.     -0.      0.      0.     -0.      0.\n",
      "   0.     -0.     -0.     -0.      0.     -0.      0.      0.     -0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.      0.     -0.      0.     -0.      0.      0.     -0.      0.\n",
      "   0.     -0.     -0.     -0.      0.     -0.      0.      0.     -0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.      0.     -0.0001  0.     -0.0001  0.0001  0.0002 -0.0001  0.\n",
      "   0.     -0.     -0.     -0.0001  0.     -0.0001  0.      0.     -0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.      0.     -0.      0.     -0.      0.      0.     -0.      0.\n",
      "   0.     -0.     -0.     -0.      0.     -0.      0.      0.     -0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.      0.     -0.      0.     -0.      0.      0.0001 -0.0001  0.\n",
      "   0.     -0.     -0.     -0.0001  0.     -0.0001  0.      0.     -0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.      0.     -0.      0.     -0.      0.      0.     -0.      0.\n",
      "   0.     -0.     -0.     -0.      0.     -0.      0.      0.     -0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.      0.     -0.      0.     -0.      0.      0.     -0.      0.\n",
      "   0.     -0.     -0.     -0.      0.     -0.      0.      0.     -0.\n",
      "  -0.     -0.      0.    ]]\n",
      "Hidden layer 5 weight_gradients is: [[ 0.      0.      0.     -0.      0.      0.      0.     -0.      0.\n",
      "   0.     -0.     -0.     -0.     -0.      0.      0.      0.     -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.      0.      0.     -0.      0.0001  0.      0.     -0.      0.\n",
      "   0.     -0.     -0.     -0.     -0.      0.      0.      0.     -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.0001  0.0002  0.0002 -0.      0.0003  0.0001  0.     -0.      0.\n",
      "   0.0002 -0.     -0.0002 -0.     -0.0001  0.      0.0003  0.0002 -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.      0.      0.     -0.      0.      0.      0.     -0.      0.\n",
      "   0.     -0.     -0.     -0.     -0.      0.      0.      0.     -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.      0.0001  0.0001 -0.      0.0001  0.      0.     -0.      0.\n",
      "   0.0001 -0.     -0.     -0.     -0.      0.      0.0001  0.     -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.0001  0.0002  0.0002 -0.      0.0002  0.0001  0.     -0.      0.\n",
      "   0.0002 -0.     -0.0001 -0.     -0.0001  0.      0.0002  0.0001 -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.0001  0.0001  0.0001 -0.      0.0001  0.      0.     -0.      0.\n",
      "   0.0001 -0.     -0.0001 -0.     -0.      0.      0.0001  0.0001 -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.      0.      0.     -0.      0.      0.      0.     -0.      0.\n",
      "   0.     -0.     -0.     -0.     -0.      0.      0.      0.     -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.0002  0.0003  0.0003 -0.      0.0004  0.0002  0.     -0.      0.\n",
      "   0.0003 -0.     -0.0002 -0.     -0.0002  0.      0.0004  0.0002 -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.      0.      0.     -0.      0.      0.      0.     -0.      0.\n",
      "   0.     -0.     -0.     -0.     -0.      0.      0.      0.     -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.      0.      0.     -0.      0.      0.      0.     -0.      0.\n",
      "   0.     -0.     -0.     -0.     -0.      0.      0.      0.     -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.      0.      0.     -0.      0.      0.      0.     -0.      0.\n",
      "   0.     -0.     -0.     -0.     -0.      0.      0.      0.     -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.0001  0.0001  0.0001 -0.      0.0002  0.0001  0.     -0.      0.\n",
      "   0.0001 -0.     -0.0001 -0.     -0.0001  0.      0.0002  0.0001 -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.      0.      0.     -0.      0.      0.      0.     -0.      0.\n",
      "   0.     -0.     -0.     -0.     -0.      0.      0.      0.     -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.      0.      0.     -0.      0.      0.      0.     -0.      0.\n",
      "   0.     -0.     -0.     -0.     -0.      0.      0.      0.     -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.      0.      0.     -0.      0.      0.      0.     -0.      0.\n",
      "   0.     -0.     -0.     -0.     -0.      0.      0.      0.     -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.      0.      0.     -0.      0.      0.      0.     -0.      0.\n",
      "   0.     -0.     -0.     -0.     -0.      0.      0.      0.     -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.      0.      0.     -0.      0.      0.      0.     -0.      0.\n",
      "   0.     -0.     -0.     -0.     -0.      0.      0.      0.     -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.      0.      0.     -0.      0.      0.      0.     -0.      0.\n",
      "   0.     -0.     -0.     -0.     -0.      0.      0.      0.     -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.      0.      0.     -0.      0.      0.      0.     -0.      0.\n",
      "   0.     -0.     -0.     -0.     -0.      0.      0.      0.     -0.\n",
      "  -0.      0.     -0.    ]\n",
      " [ 0.      0.      0.     -0.      0.      0.      0.     -0.      0.\n",
      "   0.     -0.     -0.     -0.     -0.      0.      0.      0.     -0.\n",
      "  -0.      0.     -0.    ]]\n",
      "Hidden layer 6 weight_gradients is: [[ 0.      0.      0.0007 -0.     -0.     -0.0003  0.0006  0.      0.0004\n",
      "   0.      0.0011 -0.      0.0005 -0.      0.     -0.0006  0.0004  0.\n",
      "   0.0005 -0.     -0.0007]\n",
      " [ 0.      0.      0.0005 -0.     -0.     -0.0002  0.0005  0.      0.0003\n",
      "   0.      0.0009 -0.      0.0004 -0.      0.     -0.0004  0.0003  0.\n",
      "   0.0004 -0.     -0.0005]\n",
      " [ 0.      0.      0.0004 -0.     -0.     -0.0002  0.0003  0.      0.0002\n",
      "   0.      0.0006 -0.      0.0003 -0.      0.     -0.0003  0.0002  0.\n",
      "   0.0003 -0.     -0.0004]\n",
      " [ 0.      0.      0.     -0.     -0.     -0.      0.      0.      0.\n",
      "   0.      0.     -0.      0.     -0.      0.     -0.      0.      0.\n",
      "   0.     -0.     -0.    ]\n",
      " [ 0.0001  0.      0.0012 -0.     -0.     -0.0005  0.0011  0.      0.0007\n",
      "   0.      0.002  -0.      0.0009 -0.      0.     -0.001   0.0007  0.\n",
      "   0.0008 -0.     -0.0012]\n",
      " [ 0.      0.      0.0006 -0.     -0.     -0.0003  0.0006  0.      0.0004\n",
      "   0.      0.001  -0.      0.0004 -0.      0.     -0.0005  0.0004  0.\n",
      "   0.0004 -0.     -0.0006]\n",
      " [ 0.      0.      0.     -0.     -0.     -0.      0.      0.      0.\n",
      "   0.      0.     -0.      0.     -0.      0.     -0.      0.      0.\n",
      "   0.     -0.     -0.    ]\n",
      " [ 0.      0.      0.     -0.     -0.     -0.      0.      0.      0.\n",
      "   0.      0.     -0.      0.     -0.      0.     -0.      0.      0.\n",
      "   0.     -0.     -0.    ]\n",
      " [ 0.      0.      0.     -0.     -0.     -0.      0.      0.      0.\n",
      "   0.      0.     -0.      0.     -0.      0.     -0.      0.      0.\n",
      "   0.     -0.     -0.    ]\n",
      " [ 0.      0.      0.0007 -0.     -0.     -0.0003  0.0006  0.      0.0004\n",
      "   0.      0.0011 -0.      0.0005 -0.      0.     -0.0006  0.0004  0.\n",
      "   0.0004 -0.     -0.0007]\n",
      " [ 0.      0.      0.     -0.     -0.     -0.      0.      0.      0.\n",
      "   0.      0.     -0.      0.     -0.      0.     -0.      0.      0.\n",
      "   0.     -0.     -0.    ]\n",
      " [ 0.      0.      0.0004 -0.     -0.     -0.0002  0.0004  0.      0.0002\n",
      "   0.      0.0007 -0.      0.0003 -0.      0.     -0.0003  0.0003  0.\n",
      "   0.0003 -0.     -0.0004]\n",
      " [ 0.      0.      0.     -0.     -0.     -0.      0.      0.      0.\n",
      "   0.      0.     -0.      0.     -0.      0.     -0.      0.      0.\n",
      "   0.     -0.     -0.    ]\n",
      " [ 0.      0.      0.0007 -0.     -0.     -0.0003  0.0007  0.      0.0004\n",
      "   0.      0.0012 -0.      0.0005 -0.      0.     -0.0006  0.0004  0.\n",
      "   0.0005 -0.     -0.0007]\n",
      " [ 0.      0.      0.     -0.     -0.     -0.      0.      0.      0.\n",
      "   0.      0.     -0.      0.     -0.      0.     -0.      0.      0.\n",
      "   0.     -0.     -0.    ]\n",
      " [ 0.      0.      0.0003 -0.     -0.     -0.0001  0.0003  0.      0.0002\n",
      "   0.      0.0005 -0.      0.0002 -0.      0.     -0.0002  0.0002  0.\n",
      "   0.0002 -0.     -0.0003]\n",
      " [ 0.      0.      0.0003 -0.     -0.     -0.0001  0.0002  0.      0.0002\n",
      "   0.      0.0004 -0.      0.0002 -0.      0.     -0.0002  0.0002  0.\n",
      "   0.0002 -0.     -0.0003]\n",
      " [ 0.      0.      0.     -0.     -0.     -0.      0.      0.      0.\n",
      "   0.      0.     -0.      0.     -0.      0.     -0.      0.      0.\n",
      "   0.     -0.     -0.    ]\n",
      " [ 0.      0.      0.     -0.     -0.     -0.      0.      0.      0.\n",
      "   0.      0.     -0.      0.     -0.      0.     -0.      0.      0.\n",
      "   0.     -0.     -0.    ]\n",
      " [ 0.      0.      0.     -0.     -0.     -0.      0.      0.      0.\n",
      "   0.      0.     -0.      0.     -0.      0.     -0.      0.      0.\n",
      "   0.     -0.     -0.    ]\n",
      " [ 0.      0.      0.     -0.     -0.     -0.      0.      0.      0.\n",
      "   0.      0.     -0.      0.     -0.      0.     -0.      0.      0.\n",
      "   0.     -0.     -0.    ]]\n",
      "Hidden layer 7 weight_gradients is: [[-0.0012  0.0018  0.0002 -0.      0.      0.0016 -0.      0.0018  0.0004\n",
      "   0.     -0.      0.     -0.0017  0.     -0.      0.0004 -0.     -0.\n",
      "   0.0009 -0.0026  0.0016]\n",
      " [-0.      0.      0.     -0.      0.      0.     -0.      0.      0.\n",
      "   0.     -0.      0.     -0.      0.     -0.      0.     -0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.0012  0.0018  0.0002 -0.      0.      0.0016 -0.      0.0018  0.0004\n",
      "   0.     -0.      0.     -0.0017  0.     -0.      0.0004 -0.     -0.\n",
      "   0.0009 -0.0026  0.0016]\n",
      " [-0.      0.      0.     -0.      0.      0.     -0.      0.      0.\n",
      "   0.     -0.      0.     -0.      0.     -0.      0.     -0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.      0.      0.     -0.      0.      0.     -0.      0.      0.\n",
      "   0.     -0.      0.     -0.      0.     -0.      0.     -0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.0016  0.0024  0.0003 -0.      0.      0.0021 -0.      0.0025  0.0006\n",
      "   0.0001 -0.      0.     -0.0023  0.     -0.      0.0006 -0.     -0.\n",
      "   0.0013 -0.0035  0.0022]\n",
      " [-0.0007  0.001   0.0001 -0.      0.      0.0009 -0.      0.0011  0.0002\n",
      "   0.     -0.      0.     -0.001   0.     -0.      0.0003 -0.     -0.\n",
      "   0.0005 -0.0015  0.0009]\n",
      " [-0.      0.      0.     -0.      0.      0.     -0.      0.      0.\n",
      "   0.     -0.      0.     -0.      0.     -0.      0.     -0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.0007  0.001   0.0001 -0.      0.      0.0009 -0.      0.001   0.0002\n",
      "   0.     -0.      0.     -0.001   0.     -0.      0.0003 -0.     -0.\n",
      "   0.0005 -0.0015  0.0009]\n",
      " [-0.      0.      0.     -0.      0.      0.     -0.      0.      0.\n",
      "   0.     -0.      0.     -0.      0.     -0.      0.     -0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.0013  0.0019  0.0002 -0.      0.      0.0017 -0.      0.0019  0.0004\n",
      "   0.0001 -0.      0.     -0.0018  0.     -0.      0.0005 -0.     -0.\n",
      "   0.001  -0.0028  0.0017]\n",
      " [-0.      0.      0.     -0.      0.      0.     -0.      0.      0.\n",
      "   0.     -0.      0.     -0.      0.     -0.      0.     -0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.0013  0.0019  0.0002 -0.      0.      0.0017 -0.      0.0019  0.0004\n",
      "   0.0001 -0.      0.     -0.0018  0.     -0.      0.0005 -0.     -0.\n",
      "   0.001  -0.0028  0.0017]\n",
      " [-0.      0.      0.     -0.      0.      0.     -0.      0.      0.\n",
      "   0.     -0.      0.     -0.      0.     -0.      0.     -0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.      0.      0.     -0.      0.      0.     -0.      0.      0.\n",
      "   0.     -0.      0.     -0.      0.     -0.      0.     -0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.0005  0.0007  0.0001 -0.      0.      0.0006 -0.      0.0007  0.0002\n",
      "   0.     -0.      0.     -0.0007  0.     -0.      0.0002 -0.     -0.\n",
      "   0.0004 -0.001   0.0006]\n",
      " [-0.0004  0.0007  0.0001 -0.      0.      0.0006 -0.      0.0007  0.0002\n",
      "   0.     -0.      0.     -0.0006  0.     -0.      0.0002 -0.     -0.\n",
      "   0.0004 -0.001   0.0006]\n",
      " [-0.      0.      0.     -0.      0.      0.     -0.      0.      0.\n",
      "   0.     -0.      0.     -0.      0.     -0.      0.     -0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.0001  0.0002  0.     -0.      0.      0.0001 -0.      0.0002  0.\n",
      "   0.     -0.      0.     -0.0002  0.     -0.      0.     -0.     -0.\n",
      "   0.0001 -0.0002  0.0001]\n",
      " [-0.      0.      0.     -0.      0.      0.     -0.      0.      0.\n",
      "   0.     -0.      0.     -0.      0.     -0.      0.     -0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.0004  0.0006  0.0001 -0.      0.      0.0005 -0.      0.0006  0.0001\n",
      "   0.     -0.      0.     -0.0005  0.     -0.      0.0001 -0.     -0.\n",
      "   0.0003 -0.0008  0.0005]]\n",
      "Hidden layer 8 weight_gradients is: [[ 0.     -0.     -0.0002 -0.0004  0.     -0.0004  0.      0.     -0.\n",
      "   0.      0.0004 -0.     -0.0001  0.0004 -0.     -0.0003  0.0005  0.\n",
      "  -0.0003 -0.      0.0005]\n",
      " [ 0.     -0.     -0.0032 -0.008   0.     -0.0081  0.      0.     -0.\n",
      "   0.      0.0071 -0.     -0.0011  0.0069 -0.     -0.0064  0.0095  0.\n",
      "  -0.0056 -0.      0.0088]\n",
      " [ 0.     -0.     -0.     -0.      0.     -0.      0.      0.     -0.\n",
      "   0.      0.     -0.     -0.      0.     -0.     -0.      0.      0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.     -0.     -0.     -0.      0.     -0.      0.      0.     -0.\n",
      "   0.      0.     -0.     -0.      0.     -0.     -0.      0.      0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.     -0.     -0.     -0.      0.     -0.      0.      0.     -0.\n",
      "   0.      0.     -0.     -0.      0.     -0.     -0.      0.      0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.     -0.     -0.0031 -0.0076  0.     -0.0077  0.      0.     -0.\n",
      "   0.      0.0067 -0.     -0.001   0.0066 -0.     -0.0061  0.009   0.\n",
      "  -0.0053 -0.      0.0083]\n",
      " [ 0.     -0.     -0.     -0.      0.     -0.      0.      0.     -0.\n",
      "   0.      0.     -0.     -0.      0.     -0.     -0.      0.      0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.     -0.     -0.0024 -0.006   0.     -0.006   0.      0.     -0.\n",
      "   0.      0.0053 -0.     -0.0008  0.0052 -0.     -0.0048  0.0071  0.\n",
      "  -0.0042 -0.      0.0065]\n",
      " [ 0.     -0.     -0.0025 -0.0061  0.     -0.0062  0.      0.     -0.\n",
      "   0.      0.0054 -0.     -0.0008  0.0053 -0.     -0.0049  0.0072  0.\n",
      "  -0.0043 -0.      0.0067]\n",
      " [ 0.     -0.     -0.0016 -0.004   0.     -0.004   0.      0.     -0.\n",
      "   0.      0.0036 -0.     -0.0005  0.0035 -0.     -0.0032  0.0047  0.\n",
      "  -0.0028 -0.      0.0044]\n",
      " [ 0.     -0.     -0.0036 -0.0088  0.     -0.0089  0.      0.     -0.\n",
      "   0.      0.0078 -0.     -0.0012  0.0076 -0.     -0.007   0.0104  0.\n",
      "  -0.0062 -0.      0.0097]\n",
      " [ 0.     -0.     -0.     -0.      0.     -0.      0.      0.     -0.\n",
      "   0.      0.     -0.     -0.      0.     -0.     -0.      0.      0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.     -0.     -0.0005 -0.0011  0.     -0.0012  0.      0.     -0.\n",
      "   0.      0.001  -0.     -0.0002  0.001  -0.     -0.0009  0.0014  0.\n",
      "  -0.0008 -0.      0.0013]\n",
      " [ 0.     -0.     -0.     -0.      0.     -0.      0.      0.     -0.\n",
      "   0.      0.     -0.     -0.      0.     -0.     -0.      0.      0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.     -0.     -0.     -0.      0.     -0.      0.      0.     -0.\n",
      "   0.      0.     -0.     -0.      0.     -0.     -0.      0.      0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.     -0.     -0.0005 -0.0011  0.     -0.0011  0.      0.     -0.\n",
      "   0.      0.001  -0.     -0.0001  0.001  -0.     -0.0009  0.0013  0.\n",
      "  -0.0008 -0.      0.0012]\n",
      " [ 0.     -0.     -0.     -0.      0.     -0.      0.      0.     -0.\n",
      "   0.      0.     -0.     -0.      0.     -0.     -0.      0.      0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.     -0.     -0.     -0.      0.     -0.      0.      0.     -0.\n",
      "   0.      0.     -0.     -0.      0.     -0.     -0.      0.      0.\n",
      "  -0.     -0.      0.    ]\n",
      " [ 0.     -0.     -0.0019 -0.0048  0.     -0.0048  0.      0.     -0.\n",
      "   0.      0.0043 -0.     -0.0006  0.0042 -0.     -0.0038  0.0057  0.\n",
      "  -0.0034 -0.      0.0053]\n",
      " [ 0.     -0.     -0.002  -0.0051  0.     -0.0051  0.      0.     -0.\n",
      "   0.      0.0045 -0.     -0.0007  0.0044 -0.     -0.004   0.006   0.\n",
      "  -0.0035 -0.      0.0055]\n",
      " [ 0.     -0.     -0.0007 -0.0018  0.     -0.0018  0.      0.     -0.\n",
      "   0.      0.0016 -0.     -0.0002  0.0015 -0.     -0.0014  0.0021  0.\n",
      "  -0.0013 -0.      0.002 ]]\n",
      "Hidden layer 9 weight_gradients is: [[-0.      0.     -0.     -0.      0.      0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.      0.     -0.      0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.      0.     -0.     -0.      0.      0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.      0.     -0.      0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.0029  0.018  -0.0004 -0.0063  0.      0.      0.     -0.     -0.\n",
      "  -0.0045  0.0032  0.0111  0.     -0.0074  0.     -0.      0.0117 -0.\n",
      "   0.     -0.0112  0.0044]\n",
      " [-0.0038  0.0236 -0.0006 -0.0082  0.      0.      0.     -0.     -0.\n",
      "  -0.0059  0.0041  0.0145  0.     -0.0096  0.     -0.      0.0153 -0.\n",
      "   0.     -0.0146  0.0058]\n",
      " [-0.      0.     -0.     -0.      0.      0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.      0.     -0.      0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.0009  0.0059 -0.0001 -0.0021  0.      0.      0.     -0.     -0.\n",
      "  -0.0015  0.001   0.0036  0.     -0.0024  0.     -0.      0.0038 -0.\n",
      "   0.     -0.0036  0.0014]\n",
      " [-0.      0.     -0.     -0.      0.      0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.      0.     -0.      0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.      0.     -0.     -0.      0.      0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.      0.     -0.      0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.      0.     -0.     -0.      0.      0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.      0.     -0.      0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.      0.     -0.     -0.      0.      0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.      0.     -0.      0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.0009  0.0056 -0.0001 -0.0019  0.      0.      0.     -0.     -0.\n",
      "  -0.0014  0.001   0.0034  0.     -0.0023  0.     -0.      0.0036 -0.\n",
      "   0.     -0.0035  0.0014]\n",
      " [-0.      0.     -0.     -0.      0.      0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.      0.     -0.      0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.002   0.0127 -0.0003 -0.0044  0.      0.      0.     -0.     -0.\n",
      "  -0.0032  0.0022  0.0078  0.     -0.0052  0.     -0.      0.0083 -0.\n",
      "   0.     -0.0079  0.0031]\n",
      " [-0.0013  0.0078 -0.0002 -0.0027  0.      0.      0.     -0.     -0.\n",
      "  -0.002   0.0014  0.0048  0.     -0.0032  0.     -0.      0.0051 -0.\n",
      "   0.     -0.0049  0.0019]\n",
      " [-0.      0.     -0.     -0.      0.      0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.      0.     -0.      0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.0033  0.0207 -0.0005 -0.0072  0.      0.      0.     -0.     -0.\n",
      "  -0.0052  0.0036  0.0127  0.     -0.0084  0.     -0.      0.0134 -0.\n",
      "   0.     -0.0128  0.005 ]\n",
      " [-0.0042  0.0262 -0.0006 -0.0092  0.      0.      0.     -0.     -0.\n",
      "  -0.0066  0.0046  0.0162  0.     -0.0107  0.     -0.      0.017  -0.\n",
      "   0.     -0.0163  0.0064]\n",
      " [-0.      0.     -0.     -0.      0.      0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.      0.     -0.      0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.0007  0.0045 -0.0001 -0.0016  0.      0.      0.     -0.     -0.\n",
      "  -0.0011  0.0008  0.0028  0.     -0.0018  0.     -0.      0.0029 -0.\n",
      "   0.     -0.0028  0.0011]\n",
      " [-0.      0.     -0.     -0.      0.      0.      0.     -0.     -0.\n",
      "  -0.      0.      0.      0.     -0.      0.     -0.      0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.0023  0.0143 -0.0003 -0.005   0.      0.      0.     -0.     -0.\n",
      "  -0.0036  0.0025  0.0088  0.     -0.0059  0.     -0.      0.0093 -0.\n",
      "   0.     -0.0089  0.0035]]\n",
      "Hidden layer 10 weight_gradients is: [[-0.      0.0009  0.      0.     -0.0023  0.     -0.003   0.004   0.0028\n",
      "  -0.0034 -0.004  -0.     -0.003   0.      0.     -0.     -0.0006 -0.\n",
      "   0.0023 -0.      0.0014]\n",
      " [-0.      0.0083  0.      0.     -0.0207  0.     -0.0271  0.036   0.0252\n",
      "  -0.0306 -0.0363 -0.     -0.0268  0.      0.     -0.     -0.0056 -0.\n",
      "   0.0211 -0.      0.0124]\n",
      " [-0.      0.0035  0.      0.     -0.0089  0.     -0.0116  0.0154  0.0108\n",
      "  -0.0131 -0.0156 -0.     -0.0115  0.      0.     -0.     -0.0024 -0.\n",
      "   0.009  -0.      0.0053]\n",
      " [-0.      0.0095  0.      0.     -0.0237  0.     -0.0312  0.0413  0.0289\n",
      "  -0.0352 -0.0417 -0.     -0.0308  0.      0.     -0.     -0.0064 -0.\n",
      "   0.0242 -0.      0.0142]\n",
      " [-0.      0.      0.      0.     -0.      0.     -0.      0.      0.\n",
      "  -0.     -0.     -0.     -0.      0.      0.     -0.     -0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.      0.      0.      0.     -0.      0.     -0.      0.      0.\n",
      "  -0.     -0.     -0.     -0.      0.      0.     -0.     -0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.      0.      0.      0.     -0.      0.     -0.      0.      0.\n",
      "  -0.     -0.     -0.     -0.      0.      0.     -0.     -0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.      0.      0.      0.     -0.      0.     -0.      0.      0.\n",
      "  -0.     -0.     -0.     -0.      0.      0.     -0.     -0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.      0.      0.      0.     -0.      0.     -0.      0.      0.\n",
      "  -0.     -0.     -0.     -0.      0.      0.     -0.     -0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.      0.0061  0.      0.     -0.0152  0.     -0.02    0.0265  0.0185\n",
      "  -0.0226 -0.0267 -0.     -0.0197  0.      0.     -0.     -0.0041 -0.\n",
      "   0.0155 -0.      0.0091]\n",
      " [-0.      0.0066  0.      0.     -0.0165  0.     -0.0217  0.0288  0.0202\n",
      "  -0.0245 -0.0291 -0.     -0.0215  0.      0.     -0.     -0.0045 -0.\n",
      "   0.0169 -0.      0.0099]\n",
      " [-0.      0.0003  0.      0.     -0.0008  0.     -0.001   0.0014  0.001\n",
      "  -0.0012 -0.0014 -0.     -0.001   0.      0.     -0.     -0.0002 -0.\n",
      "   0.0008 -0.      0.0005]\n",
      " [-0.      0.      0.      0.     -0.      0.     -0.      0.      0.\n",
      "  -0.     -0.     -0.     -0.      0.      0.     -0.     -0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.      0.0007  0.      0.     -0.0018  0.     -0.0024  0.0031  0.0022\n",
      "  -0.0027 -0.0031 -0.     -0.0023  0.      0.     -0.     -0.0005 -0.\n",
      "   0.0018 -0.      0.0011]\n",
      " [-0.      0.      0.      0.     -0.      0.     -0.      0.      0.\n",
      "  -0.     -0.     -0.     -0.      0.      0.     -0.     -0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.      0.      0.      0.     -0.      0.     -0.      0.      0.\n",
      "  -0.     -0.     -0.     -0.      0.      0.     -0.     -0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.      0.0005  0.      0.     -0.0013  0.     -0.0017  0.0023  0.0016\n",
      "  -0.0019 -0.0023 -0.     -0.0017  0.      0.     -0.     -0.0004 -0.\n",
      "   0.0013 -0.      0.0008]\n",
      " [-0.      0.      0.      0.     -0.      0.     -0.      0.      0.\n",
      "  -0.     -0.     -0.     -0.      0.      0.     -0.     -0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.      0.      0.      0.     -0.      0.     -0.      0.      0.\n",
      "  -0.     -0.     -0.     -0.      0.      0.     -0.     -0.     -0.\n",
      "   0.     -0.      0.    ]\n",
      " [-0.      0.0102  0.      0.     -0.0255  0.     -0.0335  0.0444  0.0311\n",
      "  -0.0378 -0.0448 -0.     -0.0331  0.      0.     -0.     -0.0069 -0.\n",
      "   0.026  -0.      0.0153]\n",
      " [-0.      0.0112  0.      0.     -0.0279  0.     -0.0367  0.0486  0.0341\n",
      "  -0.0414 -0.0491 -0.     -0.0363  0.      0.     -0.     -0.0076 -0.\n",
      "   0.0285 -0.      0.0167]]\n"
     ]
    }
   ],
   "source": [
    "# output layer\n",
    "\n",
    "dt = deri_criterion(zrm_output[-1], np.around(y.detach().numpy(),4))\n",
    "print('y.numpy: ',y.numpy())\n",
    "\n",
    "dw_out = np.dot(zrm_output[-2], dt)\n",
    "db_out = np.ones(1).dot(dt)\n",
    "print('Layer 11 bias: ',db_out)\n",
    "\n",
    "\n",
    "    \n",
    "hidden_weight_gradients = []\n",
    "hidden_bias_gradients = []\n",
    "    \n",
    "i = 10    #  i = 10\n",
    "\n",
    "# layer 10 to layer 1\n",
    "for i in range(i,0,-1):  \n",
    "    h = zrm_output[i].copy()\n",
    "    d = deri_Relu(h)\n",
    "    dt = np.dot(dt,zrm_weight[i+1].T) * d\n",
    "    \n",
    "    db = np.ones(1).dot(dt)\n",
    "    dw = np.dot(zrm_output[i-1].reshape(len(zrm_output[i-1]),1),dt)\n",
    "    hidden_weight_gradients.append(dw)\n",
    "    hidden_bias_gradients.append(db)\n",
    "\n",
    "j = 1\n",
    "for i in reversed (range(10)):\n",
    "    print(f'Hidden layer {j} bias_gradients is: {np.around(hidden_bias_gradients[i],4)}')\n",
    "    j += 1\n",
    "    \n",
    "j = 1\n",
    "for i in reversed (range(10)):\n",
    "    print(f'Hidden layer {j} weight_gradients is: {np.around(hidden_weight_gradients[i],4)}')\n",
    "    j += 1\n",
    "    \n",
    "    \n",
    "# j = 1\n",
    "# fo = open('D:/PG_study/BS6207/Assignment/my_autograd.dat', 'w')\n",
    "# for i in reversed (range(10)):\n",
    "#     fo.write('Layer '+str(j)+' my_weight is'+'\\n'+str(hidden_weight_gradients[i]))\n",
    "#     fo.write('\\n')\n",
    "#     fo.write('Layer '+str(j)+' my_bias is'+'\\n'+str(hidden_bias_gradients[i]))\n",
    "#     fo.write('\\n')\n",
    "#     j += 1\n",
    "# fo.write('Layer 11 my_weight is '+'\\n'+str(dw_out))\n",
    "# fo.write('\\n')\n",
    "# fo.write('Layer 11 my_bias is '+'\\n'+str(db_out))\n",
    "# fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-position",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-timber",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "closed-adaptation",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sharp-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchviz import make_dot\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/ProgramData/Anaconda3/Library/bin/graphviz/bin'\n",
    "\n",
    "def print_compute_tree(name,node):\n",
    "    dot = make_dot(node)\n",
    "    #print(dot)\n",
    "    dot.render(name)\n",
    "\n",
    "torch.manual_seed(2317)\n",
    "x = torch.randn([1,1,10],requires_grad=True)\n",
    "cn1 = nn.Conv1d(1,1,3,padding=1)\n",
    "fc1 = nn.Linear(10,10)\n",
    "fc2 = nn.Linear(10,1)\n",
    "y = torch.sum(x)\n",
    "c = cn1(x)\n",
    "x = torch.flatten(x)+torch.flatten(c)\n",
    "x = fc1(x)\n",
    "x = fc2(x)\n",
    "loss = torch.sum((x-y)*(x-y))\n",
    "print_compute_tree('./tree_ex' ,loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-saying",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
